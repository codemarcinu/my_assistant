"""
Syntezator Odpowiedzi - generuje finalnÄ…, spÃ³jnÄ… odpowiedÅº na podstawie wynikÃ³w wykonania planu
Zgodnie z planem ewolucji - Faza 2: RdzeÅ„ Inteligencji
"""

import logging
from typing import Any, Dict, List, Optional

from backend.core.hybrid_llm_client import hybrid_llm_client, ModelComplexity
from backend.settings import settings
from backend.agents.executor import ExecutionResult, StepResult
from backend.agents.interfaces import AgentResponse

logger = logging.getLogger(__name__)


class Synthesizer:
    """Syntezator odpowiedzi - Å‚Ä…czy wyniki krokÃ³w w spÃ³jnÄ… odpowiedÅº"""
    
    def __init__(self):
        self._initialized = False
    
    async def initialize(self) -> None:
        """Inicjalizuj syntezator"""
        if self._initialized:
            return
        
        self._initialized = True
        logger.info("Synthesizer initialized")
    
    async def generate_response(
        self, 
        execution_result: ExecutionResult,
        original_query: str,
        context: Optional[Dict[str, Any]] = None
    ) -> AgentResponse:
        """
        Generuj finalnÄ… odpowiedÅº na podstawie wynikÃ³w wykonania planu
        
        Args:
            execution_result: Wynik wykonania planu
            original_query: Oryginalne zapytanie uÅ¼ytkownika
            context: Dodatkowy kontekst
            
        Returns:
            AgentResponse z finalnÄ… odpowiedziÄ…
        """
        try:
            if not execution_result.success:
                return self._generate_error_response(execution_result, original_query)
            
            # Przygotuj dane dla syntezatora
            synthesis_data = self._prepare_synthesis_data(execution_result, context)
            
            # Wygeneruj odpowiedÅº uÅ¼ywajÄ…c LLM
            response_text = await self._synthesize_with_llm(original_query, synthesis_data)
            
            # UtwÃ³rz AgentResponse
            return AgentResponse(
                success=True,
                text=response_text,
                data={
                    "execution_summary": self._create_execution_summary(execution_result),
                    "steps_executed": len(execution_result.step_results),
                    "execution_time": execution_result.total_execution_time,
                    "plan_complexity": execution_result.plan.estimated_complexity
                }
            )
            
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return self._generate_fallback_response(execution_result, original_query)
    
    def _prepare_synthesis_data(
        self, 
        execution_result: ExecutionResult, 
        context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Przygotuj dane do syntezy odpowiedzi"""
        synthesis_data = {
            "original_query": execution_result.plan.query,
            "successful_steps": [],
            "failed_steps": [],
            "step_results": [],
            "context": context or {}
        }
        
        for i, step_result in enumerate(execution_result.step_results):
            step_info = {
                "step_number": i + 1,
                "tool": step_result.step.tool,
                "description": step_result.step.description,
                "success": step_result.success,
                "result": step_result.result,
                "execution_time": step_result.execution_time
            }
            
            synthesis_data["step_results"].append(step_info)
            
            if step_result.success:
                synthesis_data["successful_steps"].append(step_info)
            else:
                synthesis_data["failed_steps"].append(step_info)
        
        return synthesis_data
    
    async def _synthesize_with_llm(
        self, 
        original_query: str, 
        synthesis_data: Dict[str, Any]
    ) -> str:
        """Syntezuj odpowiedÅº uÅ¼ywajÄ…c LLM"""
        system_prompt = self._create_synthesizer_prompt()
        user_prompt = self._create_synthesis_user_prompt(original_query, synthesis_data)
        
        try:
            response = await hybrid_llm_client.chat(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                model=settings.DEFAULT_MODEL,
                force_complexity=ModelComplexity.STANDARD,
                stream=False,
            )
            
            if isinstance(response, dict) and response.get("message"):
                raw_response = response["message"]["content"]
                # Clean up the response to remove metadata and formatting
                cleaned_response = self._clean_synthesis_response(raw_response)
                return cleaned_response
            else:
                logger.warning("Invalid response from LLM for synthesis")
                return self._create_fallback_synthesis(original_query, synthesis_data)
                
        except Exception as e:
            logger.error(f"Error in LLM synthesis: {e}")
            return self._create_fallback_synthesis(original_query, synthesis_data)
    
    def _clean_synthesis_response(self, response: str) -> str:
        """Clean up the synthesis response to remove metadata and formatting"""
        import re
        
        # Remove common metadata patterns
        patterns_to_remove = [
            r'Original user query:.*?\n',
            r'---\s*\n',
            r'âœ…\s*Step \d+:.*?\n',
            r'âœ—\s*Step \d+:.*?\n',
            r'Response:\s*["\']?',
            r'["\']?\s*$',
            r'\*\*.*?\*\*',  # Remove bold formatting
            r'#+\s*.*?\n',   # Remove markdown headers
            r'^\s*[-*+]\s*', # Remove list markers at start
            r'^\s*\d+\.\s*', # Remove numbered lists at start
            r'ğŸ˜Š|ğŸ½ï¸|â˜•|âœ…|âœ—|ğŸ¯|ğŸ“|ğŸ’¡|ğŸ”|ğŸ“Š|ğŸ‰|ğŸ‘|ğŸ‘|â¤ï¸|ğŸ’”|ğŸ˜€|ğŸ˜ƒ|ğŸ˜„|ğŸ˜|ğŸ˜†|ğŸ˜…|ğŸ˜‚|ğŸ¤£|ğŸ˜Š|ğŸ˜‡|ğŸ™‚|ğŸ™ƒ|ğŸ˜‰|ğŸ˜Œ|ğŸ˜|ğŸ¥°|ğŸ˜˜|ğŸ˜—|ğŸ˜™|ğŸ˜š|ğŸ˜‹|ğŸ˜›|ğŸ˜|ğŸ˜œ|ğŸ¤ª|ğŸ¤¨|ğŸ§|ğŸ¤“|ğŸ˜|ğŸ¤©|ğŸ¥³|ğŸ˜|ğŸ˜’|ğŸ˜|ğŸ˜”|ğŸ˜Ÿ|ğŸ˜•|ğŸ™|â˜¹ï¸|ğŸ˜£|ğŸ˜–|ğŸ˜«|ğŸ˜©|ğŸ¥º|ğŸ˜¢|ğŸ˜­|ğŸ˜¤|ğŸ˜ |ğŸ˜¡|ğŸ¤¬|ğŸ¤¯|ğŸ˜³|ğŸ¥µ|ğŸ¥¶|ğŸ˜±|ğŸ˜¨|ğŸ˜°|ğŸ˜¥|ğŸ˜“|ğŸ¤—|ğŸ¤”|ğŸ¤­|ğŸ¤«|ğŸ¤¥|ğŸ˜¶|ğŸ˜|ğŸ˜‘|ğŸ˜¯|ğŸ˜¦|ğŸ˜§|ğŸ˜®|ğŸ˜²|ğŸ¥±|ğŸ˜´|ğŸ¤¤|ğŸ˜ª|ğŸ˜µ|ğŸ¤|ğŸ¥´|ğŸ¤¢|ğŸ¤®|ğŸ¤§|ğŸ˜·|ğŸ¤’|ğŸ¤•|ğŸ¤‘|ğŸ¤ |ğŸ’©|ğŸ‘»|ğŸ’€|â˜ ï¸|ğŸ‘½|ğŸ‘¾|ğŸ¤–|ğŸ˜º|ğŸ˜¸|ğŸ˜¹|ğŸ˜»|ğŸ˜¼|ğŸ˜½|ğŸ™€|ğŸ˜¿|ğŸ˜¾|ğŸ™ˆ|ğŸ™‰|ğŸ™Š|ğŸ‘¶|ğŸ‘§|ğŸ§’|ğŸ‘¦|ğŸ‘©|ğŸ§‘|ğŸ‘¨|ğŸ‘µ|ğŸ§“|ğŸ‘´|ğŸ‘®â€â™€ï¸|ğŸ‘®|ğŸ‘®â€â™‚ï¸|ğŸ•µï¸â€â™€ï¸|ğŸ•µï¸|ğŸ•µï¸â€â™‚ï¸|ğŸ’‚â€â™€ï¸|ğŸ’‚|ğŸ’‚â€â™‚ï¸|ğŸ‘·â€â™€ï¸|ğŸ‘·|ğŸ‘·â€â™‚ï¸|ğŸ¤´|ğŸ‘¸|ğŸ‘³â€â™€ï¸|ğŸ‘³|ğŸ‘³â€â™‚ï¸|ğŸ‘²|ğŸ§•â€â™€ï¸|ğŸ§•|ğŸ§•â€â™‚ï¸|ğŸ¤µâ€â™€ï¸|ğŸ¤µ|ğŸ¤µâ€â™‚ï¸|ğŸ‘°â€â™€ï¸|ğŸ‘°|ğŸ‘°â€â™‚ï¸|ğŸ¤°â€â™€ï¸|ğŸ¤°|ğŸ¤°â€â™‚ï¸|ğŸ¤±â€â™€ï¸|ğŸ¤±|ğŸ¤±â€â™‚ï¸|ğŸ‘¼|ğŸ…|ğŸ¤¶|ğŸ§™â€â™€ï¸|ğŸ§™|ğŸ§™â€â™‚ï¸|ğŸ§â€â™€ï¸|ğŸ§|ğŸ§â€â™‚ï¸|ğŸ§›â€â™€ï¸|ğŸ§›|ğŸ§›â€â™‚ï¸|ğŸ§Ÿâ€â™€ï¸|ğŸ§Ÿ|ğŸ§Ÿâ€â™‚ï¸|ğŸ§â€â™€ï¸|ğŸ§|ğŸ§â€â™‚ï¸|ğŸ§œâ€â™€ï¸|ğŸ§œ|ğŸ§œâ€â™‚ï¸|ğŸ§šâ€â™€ï¸|ğŸ§š|ğŸ§šâ€â™‚ï¸',  # Remove emojis
            r'\[.*?\]',  # Remove square brackets content
            r'^\s*["\']',  # Remove quotes at start
            r'["\']\s*$',  # Remove quotes at end
            r'^\s*OdpowiedÅº:\s*',  # Remove "OdpowiedÅº:" prefix
            r'^\s*Response:\s*',  # Remove "Response:" prefix
            r'^\s*Result:\s*',  # Remove "Result:" prefix
            r'Oto moja odpowiedÅº oparta na.*?\n',  # Remove Polish metadata
            r'PamiÄ™taj:.*?\n',  # Remove reminder text
        ]
        
        cleaned = response.strip()
        
        for pattern in patterns_to_remove:
            cleaned = re.sub(pattern, '', cleaned, flags=re.MULTILINE | re.DOTALL)
        
        # Remove extra whitespace and normalize
        cleaned = re.sub(r'\n\s*\n', '\n', cleaned)  # Remove multiple newlines
        cleaned = re.sub(r'^\s+', '', cleaned, flags=re.MULTILINE)  # Remove leading whitespace
        cleaned = re.sub(r'\s+$', '', cleaned, flags=re.MULTILINE)  # Remove trailing whitespace
        cleaned = cleaned.strip()
        
        # If the response is empty or too short after cleaning, use fallback
        if len(cleaned) < 10:
            logger.warning("Response too short after cleaning, using fallback")
            return "Przepraszam, wystÄ…piÅ‚ problem z generowaniem odpowiedzi."
        
        # Try to extract the actual response content from metadata-heavy responses
        if any(phrase in cleaned.lower() for phrase in ["oryginalne zapytanie", "w odpowiedzi", "original user query", "in response"]):
            # Look for quoted content that might be the actual response
            quote_match = re.search(r'["\']([^"\']+)["\']', cleaned)
            if quote_match:
                cleaned = quote_match.group(1)
            else:
                # Try to find the last sentence that might be the actual response
                sentences = cleaned.split('.')
                for sentence in reversed(sentences):
                    sentence = sentence.strip()
                    if sentence and len(sentence) > 10 and not any(phrase in sentence.lower() for phrase in ["oryginalne", "original", "w odpowiedzi", "in response"]):
                        cleaned = sentence
                        break
        
        return cleaned
    
    def _create_synthesizer_prompt(self) -> str:
        """TwÃ³rz prompt systemowy dla syntezatora"""
        return """
JesteÅ› ekspertem w syntetyzowaniu informacji i tworzeniu spÃ³jnych, naturalnych odpowiedzi.

Twoim zadaniem jest poÅ‚Ä…czenie wynikÃ³w z rÃ³Å¼nych krokÃ³w wykonania w jednÄ…, pÅ‚ynnÄ… odpowiedÅº dla uÅ¼ytkownika.

**ABSOLUTNIE KRYTYCZNE ZASADY:**
- ZAWSZE generuj TYLKO naturalnÄ…, pÅ‚ynnÄ… odpowiedÅº
- NIE dodawaj nagÅ‚Ã³wkÃ³w, list, numeracji ani formatowania
- NIE uÅ¼ywaj markdown, emoji ani specjalnych znakÃ³w
- NIE dodawaj metadanych, opisÃ³w krokÃ³w ani informacji technicznych
- NIE zaczynaj od "Oryginalne zapytanie" ani podobnych prefiksÃ³w
- NIE dodawaj informacji o krokach wykonania
- NIE uÅ¼ywaj emoji, symboli ani specjalnych znakÃ³w
- NIE dodawaj nawiasÃ³w kwadratowych ani okrÄ…gÅ‚ych z metadanymi
- OdpowiedÅº powinna brzmieÄ‡ jak naturalna konwersacja

Zasady syntezy:
1. OdpowiedÅº powinna byÄ‡ naturalna i pÅ‚ynna, jakby byÅ‚a napisana przez czÅ‚owieka
2. UwzglÄ™dnij wszystkie istotne informacje z wykonanych krokÃ³w
3. JeÅ›li niektÃ³re kroki siÄ™ nie powiodÅ‚y, wyjaÅ›nij to w odpowiedzi
4. UÅ¼ywaj kontekstu rozmowy jeÅ›li jest dostÄ™pny
5. OdpowiedÅº powinna byÄ‡ dostosowana do stylu rozmowy uÅ¼ytkownika
6. JeÅ›li zapytanie wymagaÅ‚o kilku krokÃ³w, wyjaÅ›nij logicznie poÅ‚Ä…czenie miÄ™dzy nimi
7. BÄ…dÅº pomocny i przyjazny

PrzykÅ‚ady:
- Zapytanie: "Jaka jest pogoda?" â†’ "Dzisiaj jest sÅ‚onecznie, temperatura 22Â°C"
- Zapytanie: "Przepis na kurczaka" â†’ "Oto prosty przepis na kurczaka: potrzebujesz..."
- Zapytanie: "Hello, how are you?" â†’ "CzeÅ›Ä‡! Mam siÄ™ dobrze, dziÄ™kujÄ™ za pytanie. A Ty?"

**PAMIÄ˜TAJ: ZwrÃ³Ä‡ TYLKO naturalnÄ… odpowiedÅº, bez Å¼adnych dodatkowych informacji, metadanych, emoji ani formatowania!**
"""
    
    def _create_synthesis_user_prompt(
        self, 
        original_query: str, 
        synthesis_data: Dict[str, Any]
    ) -> str:
        """TwÃ³rz prompt uÅ¼ytkownika dla syntezy"""
        prompt = f"Oryginalne zapytanie uÅ¼ytkownika: {original_query}\n\n"
        
        # Dodaj informacje o kontekÅ›cie
        if synthesis_data.get("context"):
            context = synthesis_data["context"]
            if context.get("conversation_summary"):
                prompt += f"Kontekst rozmowy: {context['conversation_summary']}\n\n"
            if context.get("user_preferences"):
                prompt += f"Preferencje uÅ¼ytkownika: {context['user_preferences']}\n\n"
        
        # Dodaj informacje o wykonanych krokach
        prompt += "Wykonane kroki:\n"
        for step_info in synthesis_data["step_results"]:
            status = "âœ“" if step_info["success"] else "âœ—"
            prompt += f"{status} Krok {step_info['step_number']}: {step_info['description']}\n"
            if step_info["success"] and step_info["result"]:
                prompt += f"   Wynik: {step_info['result']}\n"
            elif not step_info["success"]:
                prompt += f"   BÅ‚Ä…d: Krok siÄ™ nie powiÃ³dÅ‚\n"
            prompt += "\n"
        
        prompt += "StwÃ³rz spÃ³jnÄ…, naturalnÄ… odpowiedÅº dla uÅ¼ytkownika na podstawie powyÅ¼szych informacji:"
        return prompt
    
    def _create_fallback_synthesis(
        self, 
        original_query: str, 
        synthesis_data: Dict[str, Any]
    ) -> str:
        """TwÃ³rz podstawowÄ… syntezÄ™ bez LLM"""
        successful_results = [step["result"] for step in synthesis_data["successful_steps"] if step["result"]]
        
        if not successful_results:
            return "Przepraszam, nie udaÅ‚o siÄ™ przetworzyÄ‡ Twojego zapytania. WystÄ…piÅ‚y bÅ‚Ä™dy podczas wykonywania zadania."
        
        if len(successful_results) == 1:
            return str(successful_results[0])
        
        # PoÅ‚Ä…cz wyniki w prosty sposÃ³b
        response = f"Oto wyniki dla Twojego zapytania '{original_query}':\n\n"
        for i, result in enumerate(successful_results, 1):
            response += f"{i}. {result}\n\n"
        
        return response
    
    def _generate_error_response(
        self, 
        execution_result: ExecutionResult, 
        original_query: str
    ) -> AgentResponse:
        """Generuj odpowiedÅº bÅ‚Ä™du"""
        error_message = f"Przepraszam, wystÄ…piÅ‚y bÅ‚Ä™dy podczas przetwarzania zapytania '{original_query}'.\n\n"
        
        if execution_result.errors:
            error_message += "BÅ‚Ä™dy:\n"
            for error in execution_result.errors:
                error_message += f"- {error}\n"
        
        successful_steps = [r for r in execution_result.step_results if r.success]
        if successful_steps:
            error_message += f"\nUdaÅ‚o siÄ™ wykonaÄ‡ {len(successful_steps)} z {len(execution_result.step_results)} krokÃ³w."
        
        return AgentResponse(
            success=False,
            text=error_message,
            error="Plan execution failed",
            data={
                "execution_summary": self._create_execution_summary(execution_result),
                "errors": execution_result.errors,
                "successful_steps": len(successful_steps),
                "total_steps": len(execution_result.step_results)
            }
        )
    
    def _generate_fallback_response(
        self, 
        execution_result: ExecutionResult, 
        original_query: str
    ) -> AgentResponse:
        """Generuj odpowiedÅº awaryjnÄ…"""
        return AgentResponse(
            success=False,
            text=f"Przepraszam, wystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d podczas przetwarzania zapytania '{original_query}'. SprÃ³buj ponownie.",
            error="Synthesis failed",
            data={
                "execution_summary": self._create_execution_summary(execution_result)
            }
        )
    
    def _create_execution_summary(self, execution_result: ExecutionResult) -> Dict[str, Any]:
        """TwÃ³rz podsumowanie wykonania"""
        successful_steps = [r for r in execution_result.step_results if r.success]
        
        return {
            "total_steps": len(execution_result.step_results),
            "successful_steps": len(successful_steps),
            "failed_steps": len(execution_result.step_results) - len(successful_steps),
            "execution_time": execution_result.total_execution_time,
            "complexity": execution_result.plan.estimated_complexity,
            "errors": execution_result.errors
        } 