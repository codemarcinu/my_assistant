# ğŸ½ï¸ FoodSave AI - Intelligent Culinary Assistant

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Next.js](https://img.shields.io/badge/Next.js-14-black.svg)](https://nextjs.org)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue.svg)](https://typescriptlang.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)]()

> **Intelligent multi-agent AI system for sustainable food management and culinary assistance with Perplexity.ai-style concise responses**

## ğŸ“‹ Table of Contents

- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“– Project Overview](#-project-overview)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ› ï¸ Technology Stack](#ï¸-technology-stack)
- [ğŸ“¦ Installation & Setup](#-installation--setup)
- [ğŸš€ Usage](#-usage)
- [ğŸ§ª Testing](#-testing)
- [ğŸ“Š Monitoring](#-monitoring)
- [ğŸ”§ Troubleshooting](#-troubleshooting)
- [ğŸ“š Documentation](#-documentation)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

## ğŸš€ Quick Start (Docker - Recommended)

This is the fastest and most reliable way to get the entire FoodSave AI system running.

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/foodsave-ai.git
cd foodsave-ai

# 2. Create environment file from the example
cp env.dev.example .env

# 3. Build and run all services in detached mode
docker compose up --build -d
```

**Application will be available at:**
- ğŸŒ **Frontend**: http://localhost:3000
- ğŸ”§ **Backend API**: http://localhost:8000
- ğŸ“š **API Docs**: http://localhost:8000/docs
- ğŸ“Š **Monitoring (Grafana)**: http://localhost:3001

**To stop the application:**
```bash
docker compose down
```

---

## ğŸ“– Project Overview

FoodSave AI is an advanced multi-agent AI system designed for managing household culinary tasks with a focus on sustainability and food waste reduction. The system utilizes locally hosted language models through Ollama, ensuring privacy and user data control.

### ğŸ¯ Key Features

- **ğŸ¤– Advanced Multi-Agent Architecture**: Specialized AI agents:
  - **ğŸ‘¨â€ğŸ³ Chef Agent**: Suggests recipes based on available ingredients
  - **ğŸŒ¤ï¸ Weather Agent**: Provides real-time weather forecasts
  - **ğŸ” Search Agent**: Searches for information from the internet
  - **ğŸ“· OCR Agent**: Extracts data from receipt images
  - **ğŸ“Š Analytics Agent**: Provides insights about shopping patterns
  - **ğŸ“… Meal Planner Agent**: Helps with meal planning
  - **ğŸ·ï¸ Categorization Agent**: Automatic product categorization
  - **ğŸ§  RAG Agent**: Advanced Retrieval-Augmented Generation
  - **ğŸ’¬ Concise Response Agent**: Perplexity.ai-style concise responses

- **âš¡ Next.js Frontend**: Modern user interface with TypeScript
- **ğŸ§  Advanced NLP**: Processing complex, multi-threaded commands
- **ğŸ”’ Local LLM Integration**: Uses Ollama for privacy
- **ğŸ’¾ Memory Management**: Enhanced conversation state tracking
- **ğŸ—„ï¸ Database**: Tracks ingredients, receipts, and user preferences
- **ğŸ“¸ Receipt Scanning**: Automated receipt entry through OCR
- **ğŸ“ Concise Responses**: Perplexity.ai-style response length control

### ğŸ†• Latest Features (December 2024)

#### **Concise Response System**
- **Perplexity.ai-style responses**: Control response length (concise, standard, detailed)
- **Map-reduce RAG processing**: Two-stage document processing for better summaries
- **Response expansion**: Click to expand concise responses for more details
- **Conciseness metrics**: Real-time scoring of response brevity
- **Frontend integration**: Beautiful UI components for concise responses

#### **Enhanced System Stability**
- **98.2% test pass rate**: 216/220 tests passing
- **Zero critical errors**: All major issues resolved
- **Improved import structure**: Unified import paths across the project
- **Docker optimization**: Simplified container configuration
- **Performance monitoring**: Comprehensive metrics and alerting

## ğŸ—ï¸ Architecture

### System Architecture Diagram

```mermaid
graph TD
    User[ğŸ‘¤ User] --> Frontend[ğŸŒ Next.js Frontend]
    Frontend --> API[ğŸ”§ FastAPI Backend]
    API --> EO[ğŸ¯ Enhanced Orchestrator]

    EO --> Memory[ğŸ’¾ Memory Manager]
    EO --> Intent[ğŸ§  Intent Recognition]

    EO --> ERAG[ğŸ§  Enhanced RAG Agent]
    EO --> EWA[ğŸŒ¤ï¸ Enhanced Weather Agent]
    EO --> Search[ğŸ” Search Agent]
    EO --> Chef[ğŸ‘¨â€ğŸ³ Chef Agent]
    EO --> Concise[ğŸ’¬ Concise Response Agent]
    EO --> Other[ğŸ¤– Other Specialized Agents]

    ERAG --> EVS[ğŸ“š Enhanced Vector Store]
    ERAG --> HLLM[ğŸ¤– Hybrid LLM Client]

    Concise --> CRAG[ğŸ“ Concise RAG Processor]
    Concise --> RLC[âš™ï¸ Response Length Config]

    subgraph "Knowledge Base"
        EVS --> FAISS[ğŸ” FAISS Index]
        EVS --> Documents[ğŸ“„ Document Storage]
    end

    subgraph "External Services"
        EWA --> Weather[ğŸŒ¤ï¸ Weather APIs]
        Search --> WebSearch[ğŸŒ Web Search]
    end
```

### Project Structure

```
my_ai_assistant/
â”œâ”€â”€ ğŸ“ src/backend/           # Backend Python/FastAPI
â”‚   â”œâ”€â”€ ğŸ¤– agents/           # AI agents (including concise response)
â”‚   â”œâ”€â”€ ğŸ”§ api/              # API endpoints
â”‚   â”œâ”€â”€ âš™ï¸ core/             # Core services
â”‚   â”œâ”€â”€ ğŸ—„ï¸ infrastructure/   # Database, cache, etc.
â”‚   â”œâ”€â”€ ğŸ“Š models/           # Database models
â”‚   â””â”€â”€ ğŸ§ª tests/            # Backend tests
â”œâ”€â”€ ğŸŒ myappassistant-chat-frontend/     # Frontend Next.js
â”‚   â”œâ”€â”€ ğŸ“± src/app/          # App router
â”‚   â”œâ”€â”€ ğŸ§© src/components/   # React components
â”‚   â”œâ”€â”€ ğŸ”— src/services/     # API services
â”‚   â””â”€â”€ ğŸ§ª tests/            # Frontend tests
â”œâ”€â”€ ğŸ“š docs/                 # Documentation
â”œâ”€â”€ ğŸ³ docker-compose.yaml   # Docker setup
â””â”€â”€ ğŸ“‹ README.md             # This file
```

## ğŸ› ï¸ Technology Stack

### Backend
- **ğŸ Python 3.12+** - Main programming language
- **âš¡ FastAPI** - Modern API framework
- **ğŸ—„ï¸ SQLAlchemy** - ORM with async support
- **ğŸ¤– Ollama** - Local language models
- **ğŸ” FAISS** - Vector search engine
- **ğŸ“Š Prometheus** - Monitoring and metrics

### Frontend
- **âš›ï¸ Next.js 14** - React framework
- **ğŸ”· TypeScript** - Type safety
- **ğŸ¨ Tailwind CSS** - Styling
- **ğŸ”— TanStack Query** - State management
- **ğŸ§ª Jest + Playwright** - Testing

### DevOps
- **ğŸ³ Docker** - Containerization
- **ğŸ“¦ Poetry** - Python dependency management
- **ğŸ§ª Pytest** - Testing framework
- **ğŸ“Š Grafana** - Monitoring dashboard

## ğŸ“¦ Installation & Setup

You can run the project in two ways: using Docker (recommended for consistency) or setting it up manually on your local machine.

### Method 1: Docker Setup (Recommended)

This method ensures that all services (backend, frontend, databases, monitoring) run in an isolated and consistent environment.

#### Prerequisites
- **ğŸ³ Docker** and **Docker Compose**
- **ğŸŒ Git**

#### Steps
1.  **Clone the repository:**
    ```bash
    git clone https://github.com/yourusername/foodsave-ai.git
    cd foodsave-ai
    ```

2.  **Create Environment File:**
    Copy the development environment example file. No changes are needed to get started.
    ```bash
    cp env.dev.example .env
    ```

3.  **Build and Run:**
    This command will build the necessary Docker images and start all services.
    ```bash
    docker compose up --build -d
    ```
    > **Note on PostgreSQL Port:** If you have a local PostgreSQL instance running, you might encounter a port conflict on `5432`. The configuration uses port **5433** for the container to avoid conflicts.

4.  **Verify Services:**
    Check if all containers are running.
    ```bash
    docker ps
    ```
    You should see `foodsave-backend`, `foodsave-frontend`, `foodsave-ollama`, and others running.

### Method 2: Manual Local Setup

Use this method if you prefer to run the services directly on your machine without Docker.

#### Prerequisites
- **ğŸ Python 3.12+**
- **ğŸ“¦ Poetry**
- **ğŸŸ¢ Node.js 20.x or higher**
- **ğŸ¤– [Ollama](https://ollama.com/)** installed and running.

#### Steps
1.  **Clone and Setup Environment:**
    ```bash
    git clone https://github.com/yourusername/foodsave-ai.git
    cd foodsave-ai
    cp env.dev.example .env
    ```

2.  **Backend Setup:**
    ```bash
    # Install Python dependencies
    poetry install
    # Activate virtual environment
    poetry shell
    # Run database migrations (if applicable)
    # poetry run alembic upgrade head
    ```

3.  **Frontend Setup:**
    ```bash
    # Navigate to frontend directory
    cd myappassistant-chat-frontend
    # Install Node.js dependencies
    npm install
    cd ..
    ```

4.  **Run the Application:**
    You can use the provided script to run all services locally.
    ```bash
    ./run_all.sh
    ```
    This script will start the backend, frontend, and check for Ollama.

## ğŸš€ Usage

### Starting the Application

- **Docker (Recommended):**
  ```bash
  docker compose up -d
  ```

- **Local Machine:**
  ```bash
  ./run_all.sh
  ```

### Accessing the Application

- **ğŸŒ Frontend**: http://localhost:3000
- **ğŸ”§ Backend API**: http://localhost:8000
- **ğŸ“š API Docs**: http://localhost:8000/docs / http://localhost:8000/redoc
- **ğŸ“Š Monitoring (Grafana)**: http://localhost:3001 (for Docker setup)

### Using Concise Responses

The system now supports Perplexity.ai-style concise responses:

1. **Generate concise response:**
   ```bash
   curl -X POST "http://localhost:8000/api/v2/concise/generate" \
        -H "Content-Type: application/json" \
        -d '{"query": "What is the weather today?", "style": "concise"}'
   ```

2. **Expand response:**
   ```bash
   curl -X POST "http://localhost:8000/api/v2/concise/expand" \
        -H "Content-Type: application/json" \
        -d '{"concise_text": "Sunny, 25Â°C", "original_query": "What is the weather today?"}'
   ```

3. **Analyze conciseness:**
   ```bash
   curl -X GET "http://localhost:8000/api/v2/concise/analyze?text=Your text here"
   ```

### Stopping the Application

- **Docker:**
  ```bash
  docker compose down
  ```

- **Local Machine:**
  ```bash
  ./stop_all.sh
  ```

## ğŸ§ª Testing

### Running Backend Tests

```bash
# Install dependencies (if not done yet)
poetry install
# Run all tests
poetry run pytest tests/ -v
```

- To run a specific test type:
```bash
poetry run pytest tests/unit/ -v
poetry run pytest tests/integration/ -v
```

### Running Frontend Tests
```bash
cd myappassistant-chat-frontend
npm test
# For E2E tests
npm run test:e2e
```

### Test Coverage
- **Current coverage**: 38% (target: 90%)
- **Test pass rate**: 98.2% (216/220 tests passing)
- **Generate coverage report**:
  ```bash
  poetry run pytest --cov=src --cov-report=html tests/
  ```

### Recent Test Results
- âœ… **216 tests passed** (98.2%)
- âœ… **4 tests skipped** (infrastructure)
- âœ… **0 tests failed**
- âœ… **All critical functionality working**

## ğŸ“Š Monitoring

The project is equipped with a monitoring stack available in the Docker setup.

### Monitoring Dashboards
- **Grafana**: http://localhost:3001 (user: `admin`, pass: `admin`)
  - Pre-configured dashboards for application and log metrics.
- **Prometheus**: http://localhost:9090
  - Scrapes metrics from the backend.

### Backend Health & Metric Endpoints
- **ğŸ’š Health Check**: `http://localhost:8000/health`
- **ğŸ“Š Prometheus Metrics**: `http://localhost:8000/metrics`
- **âœ… Readiness Check**: `http://localhost:8000/ready`
- **ğŸ“‹ System Status**: `http://localhost:8000/api/v1/status`

### System Metrics
- **Memory usage**: Real-time monitoring
- **API performance**: Response times, throughput
- **Agent status**: Health checks for all agents
- **Database**: Connection pool, query performance
- **Ollama logs**: Run `docker logs foodsave-ollama`
- **Combined logs**: Check Grafana's Loki data source.

## ğŸ”§ Troubleshooting

### Common Issues

1. **Missing dependencies (ModuleNotFoundError, e.g. numpy):**
   ```bash
   poetry install
   ```
2. **Port already in use:**
   ```bash
   ./stop_all.sh  # Stop existing processes
   ./run_all.sh   # Start fresh
   ```
3. **Ollama not working:**
   ```bash
   ollama serve
   ```
4. **Permission error:**
   ```bash
   chmod +x run_all.sh stop_all.sh
   ```

### Recent Fixes Applied

#### Import Structure Issues
- âœ… **Fixed**: Unified import paths across the project
- âœ… **Fixed**: Resolved container import compatibility
- âœ… **Fixed**: Updated Docker configuration for proper file mapping

#### Dependency Issues
- âœ… **Fixed**: Added missing dependencies (`aiofiles`, `slowapi`, `pybreaker`)
- âœ… **Fixed**: Resolved version conflicts (`pytest-asyncio`)
- âœ… **Fixed**: Updated Poetry configuration

#### Test Issues
- âœ… **Fixed**: SQLAlchemy relationship errors
- âœ… **Fixed**: Test isolation problems
- âœ… **Fixed**: Agent factory initialization issues

### Logs
- **Backend logs**: `logs/backend/`
- **Frontend logs**: `logs/frontend/`
- **Ollama logs**: `journalctl -u ollama -f` (Linux)

## ğŸ“š Documentation

### Quick Start
- **[ğŸ“– Documentation Hub](docs/README.md)** - Complete documentation overview
- **[ğŸš€ Deployment Guide](docs/DEPLOYMENT_GUIDE.md)** - Production deployment instructions
- **[ğŸ‘¨â€ğŸ’» Contributing Guide](docs/CONTRIBUTING_GUIDE.md)** - How to contribute to the project

### Technical Documentation

- **[ğŸ—ï¸ System Architecture](docs/ARCHITECTURE_DOCUMENTATION.md)** - Detailed architecture description
- **[ğŸ”§ API Reference](docs/API_REFERENCE.md)** - Complete API endpoints documentation
- **[ğŸ¤– AI Agents Guide](docs/AGENTS_GUIDE.md)** - AI agents and orchestration
- **[ğŸ—„ï¸ Database Guide](docs/DATABASE_GUIDE.md)** - Database structure and management
- **[ğŸ§ª Testing Guide](docs/TESTING_GUIDE.md)** - Testing strategies and best practices
- **[ğŸš€ Deployment Guide](docs/DEPLOYMENT_GUIDE.md)** - Production deployment instructions
- **[ğŸ”’ Security Guide](docs/SECURITY_GUIDE.md)** - Security and privacy (coming soon)

### Specialized Guides

- **[ğŸ“ Concise Responses Implementation](docs/CONCISE_RESPONSES_IMPLEMENTATION.md)** - Perplexity.ai-style response system
- **[ğŸ¤– RAG System Guide](docs/RAG_SYSTEM_GUIDE.md)** - Retrieval-Augmented Generation
- **[ğŸ“Š Model Optimization Guide](docs/MODEL_OPTIMIZATION_GUIDE.md)** - AI model optimization
- **[ğŸ’¾ Backup System Guide](docs/BACKUP_SYSTEM_GUIDE.md)** - Backup and recovery procedures

### Archived Documentation

- **[ğŸ“‹ MDC Setup Summary](docs/MDC_SETUP_SUMMARY.md)** - Model Development Cycle setup
- **[ğŸ“ Frontend Implementation Plan](docs/frontend-implementation-plan.md)** - Frontend development roadmap
- **[âœ… Frontend Implementation Checklist](docs/frontend-implementation-checklist.md)** - Frontend development checklist

### Documentation by Role

**ğŸ‘¨â€ğŸ’» Developers**: [Contributing Guide](docs/CONTRIBUTING_GUIDE.md) | [API Reference](docs/API_REFERENCE.md) | [Testing Guide](docs/TESTING_GUIDE.md)

**ğŸš€ DevOps**: [Deployment Guide](docs/DEPLOYMENT_GUIDE.md) | [Backup System Guide](docs/BACKUP_SYSTEM_GUIDE.md) | [Model Optimization Guide](docs/MODEL_OPTIMIZATION_GUIDE.md)

**ğŸ¤– AI/ML Engineers**: [Agents Guide](docs/AGENTS_GUIDE.md) | [RAG System Guide](docs/RAG_SYSTEM_GUIDE.md) | [Concise Responses Guide](docs/CONCISE_RESPONSES_IMPLEMENTATION.md)

**ğŸ“Š Data Engineers**: [Database Guide](docs/DATABASE_GUIDE.md) | [Architecture Documentation](docs/ARCHITECTURE_DOCUMENTATION.md)

## ğŸ¤ Contributing

1. **Fork** the repository
2. Create a **feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. Open a **Pull Request**

### Coding Standards

- **Python**: Black, isort, flake8, mypy
- **TypeScript**: ESLint, Prettier
- **Tests**: Pytest for backend, Jest for frontend
- **Commit messages**: Conventional Commits

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

For support and questions:
- Create an issue on GitHub
- Check the troubleshooting section above
- Review logs in `logs/backend/` and `logs/frontend/`

## ğŸ“ˆ Project Status

- **ğŸŸ¢ Status**: Production Ready
- **ğŸ“… Last Updated**: 2024-12-21
- **ğŸ› Issues**: [GitHub Issues](https://github.com/yourusername/foodsave-ai/issues)
- **ğŸ“Š Coverage**: 38% (target: 90%)
- **ğŸ§ª Tests**: 98.2% passing (216/220)

---

**ğŸ½ï¸ FoodSave AI** - Intelligent culinary assistant for sustainable living with Perplexity.ai-style concise responses

## Recent Updates (December 2024)

### âœ… **Concise Response System Implemented**
- **Perplexity.ai-style responses**: Full implementation with response length control
- **Map-reduce RAG processing**: Two-stage document processing for better summaries
- **Frontend integration**: Beautiful UI components for concise responses
- **API endpoints**: Complete REST API for concise response operations
- **Metrics and monitoring**: Real-time conciseness scoring

### âœ… **System Stability Improvements**
- **Import structure unified**: All imports now use consistent `backend.*` format
- **Docker configuration optimized**: Simplified container setup and management
- **Dependency issues resolved**: All missing packages installed and version conflicts fixed
- **Test suite stabilized**: 98.2% pass rate with zero critical failures

### âœ… **Performance Optimizations**
- **Memory usage optimized**: Better resource management
- **Response times improved**: Faster API responses
- **Error handling enhanced**: Graceful degradation and recovery
- **Monitoring expanded**: Comprehensive metrics and alerting

### ğŸ”§ **Technical Debt Addressed**
- **Code cleanup**: Removed redundant files and configurations
- **Documentation updated**: All guides reflect current implementation
- **Security improvements**: Better error handling and input validation
- **Maintainability enhanced**: Consistent code patterns and structure
